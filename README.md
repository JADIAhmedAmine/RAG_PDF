# ğŸ“„ RAG_PDF â€” Pipeline RAG multimodal pour lâ€™analyse de PDF (Qwen)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)
![Project](https://img.shields.io/badge/Multimodal-RAG-purple)
![Status](https://img.shields.io/badge/Stage-ATLANTASANAD-orange)

**RAG_PDF** est un pipeline **RAG (Retrieval-Augmented Generation)** multimodal pour analyser des **PDF non structurÃ©s**  
(texte, tableaux, graphiques, schÃ©mas) et rÃ©pondre Ã  des questions en **langage naturel**, avec une UI Gradio et des mÃ©canismes de **cache**.

Il combine **Docling** (extraction), **Qwen3** (embeddings + gÃ©nÃ©ration), **CLIP** (sÃ©lection dâ€™images) et **Qwen-VL** (raisonnement visuel).  
Tout le traitement est **local** par dÃ©faut.


---

## 

Ce projet met en avant une maÃ®trise complÃ¨te dâ€™une chaÃ®ne **document AI** orientÃ©e production :

- **Extraction PDF** rÃ©aliste et structurÃ©e.
- **RAG multimodal** (texte + tableaux + figures).
- **Recherche sÃ©mantique** + **reranking** pour la pertinence.
- **IntÃ©gration VLM** pour raisonner sur graphiques/schÃ©mas.
- **IngÃ©nierie solide** : architecture modulaire, caching, logs, UI unifiÃ©e.

---

##  FonctionnalitÃ©s

- **Extraction PDF robuste** â†’ Markdown (texte + tableaux + *captions dâ€™images*).
- **Chunking intelligent** conservant tables & lÃ©gendes.
- **Recherche sÃ©mantique** (embeddings Qwen3 + FAISS/KNN + *rerank* cross-encoder).
- **Vision-LLM** (Qwen-VL quantisÃ© 4-bit, fallback GPU/CPU).
- **SÃ©lection dâ€™images zero-shot** (CLIP) : `chart / table / diagram / flowchart`.
- **UI Gradio unifiÃ©e** avec logs, diagnostic JSON et export Markdown.
- **Caches** sÃ©parÃ©s par mode + nettoyage auto des images temporaires.


## Organisation

```
qwenpdf_insight/
â”œâ”€â”€ app/                       # Interface Gradio unifiÃ©e
â”‚   â””â”€â”€ qwen_interface_unified.py
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”œâ”€â”€ extract_with_docling.py
â”‚   â”‚   â””â”€â”€ extract_with_docling_img.py
â”‚   â”œâ”€â”€ embedding/qwen_embedding.py
â”‚   â”œâ”€â”€ generation/generate_qwen_answer.py
â”‚   â””â”€â”€ multimodal/image_qa_pipeline.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ launch_gradio.py
â”‚   â”œâ”€â”€ launch_gradio_img.py
â”‚   â””â”€â”€ launch_unified.py         # â† script de lancement recommandÃ©
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/    # PDF (hashÃ©s)
â”‚   â”œâ”€â”€ markdown/   # Exports Docling
â”‚   â”œâ”€â”€ chunks/     # Chunks concatÃ©nÃ©s
â”‚   â”œâ”€â”€ cache/      # cache (text-only)
â”‚   â”œâ”€â”€ cache_img/  # cache (text-image & ++)
â”‚   â”œâ”€â”€ images/     # figures/rendu (temp)
â”‚   â””â”€â”€ logs/       # interface_log.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

##  PrÃ©requis

- **OS** : Linux, macOS, Windows 10/11
- **Python** : 3.10+
- **GPU (optionnel)** : CUDA 11.8+ recommandÃ© pour Qwen-VL 4-bit
- **Disk** : prÃ©voir de lâ€™espace pour `data/` (exports, caches, images)

---

##  Installation

```bash
git clone https://github.com/JADIAhmedAmine/RAG_PDF.git
cd qwenpdf_insight
python -m venv .venv && source .venv/bin/activate     # PowerShell: .venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

Connexion Hugging Face si besoin :

```bash
huggingface-cli login
```

### ModÃ¨les utilisÃ©s

- `Qwen/Qwen3-Embedding-0.6B`
- `Qwen/Qwen3-0.6B` (ou `Qwen/Qwen3-0.6B-Chat`)
- `cross-encoder/ms-marco-MiniLM-L-6-v2`
- `laion/CLIP-ViT-B-32-laion2B-s34B-b79K`
- `Qwen/Qwen2.5-VL-3B-Instruct`

---

## â–¶ Lancement

### Windows (PowerShell / CMD)

```bash
py .\scripts\launch_unified.py
```

### Linux / macOS

```bash
python scripts/launch_unified.py
```

**Modes** (sÃ©lection dans lâ€™UI) :
- `text-only` â€” plus rapide, 100% textuel.
- `text-image-with-docling` â€” ajoute *captions* dâ€™images (sans VLM).
- `text-image++` â€” multimodal complet (extraction figures â†’ CLIP â†’ Qwen-VL).

**Sorties UI** : rÃ©ponse gÃ©nÃ©rÃ©e, passages *Top-k*, rÃ©sumÃ© VLM (mode ++), galerie dâ€™images, log tÃ©lÃ©chargeable, export **Markdown**.

---

##  ParamÃ¨tres utiles (sans casser le cache)

- `k_images = 4` â€” nb dâ€™images passÃ©es Ã  Qwen-VL  
- `min_prob = 0.18` â€” seuil CLIP  
- `page_dpi = 180` â€” rendu de pages (vectoriels)  
- `extract_full_pages = false` â€” rendu page entiÃ¨re si besoin  

**Env conseillÃ©s**

```bash
# logs console (DEBUG/INFO/WARNING/ERROR)
export LOGLEVEL=INFO
# limiter la fragmentation CUDA
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
```

---

##  Caching & perfs

| Mode                      | Extraction Docling                     | Cache embeddings | Dossier cache    | VLM Qwen-VL       | Images persistÃ©es        |
|---------------------------|----------------------------------------|------------------|------------------|-------------------|--------------------------|
| `text-only`               | Texte + tableaux                       | âœ…                | `data/cache`     | âŒ                 | â€”                        |
| `text-image-with-docling` | Texte + tableaux + *captions*          | âœ…                | `data/cache_img` | Auto (si requise) | `data/images/<hash>`     |
| `text-image++`            | Idem + **force VLM**                   | âœ… (texte)        | `data/cache_img` | âœ… (forcÃ©e)        | Non (nettoyage auto)     |

**ClÃ© de cache** : hash **SHA-256** du PDF (gÃ©rÃ© par `EmbeddingCacheManager`). Lâ€™index est **reconstruit** Ã  la volÃ©e depuis les embeddings.

---
---

##  Exemple dâ€™exÃ©cution â€” Analyse automatique de CV

Chargement du PDF â†’ extraction â†’ rÃ©sumÃ© orientÃ© recrutement  
GÃ©nÃ©ration dâ€™un profil professionnel court + points forts + sugg. de postes

<p align="center">
  <img src="docs/screenshots/demo_cv_analysis.png" width="85%" alt="Analyse automatique de CV"/>
</p>

---
### Exemple d'exÃ©cution interne (Debug Pipeline)

Cet extrait illustre le fonctionnement complet du pipeline lors dâ€™une analyse de document.
On observe clairement les Ã©tapes successives du traitement RAG :

1. **Extraction PDF (Docling)** â†’ conversion en Markdown structurÃ©  
2. **Chunking** â†’ segmentation du contenu en blocs exploitables  
3. **Embeddings (Qwen3)** â†’ vectorisation pour la recherche sÃ©mantique  
4. **Retrieval Top-K** â†’ sÃ©lection des passages pertinents  
5. **Classification de la requÃªte** (ici â†’ RÃ©sumÃ© CV, confiance = 0.995)  
6. **GÃ©nÃ©ration finale** â†’ rÃ©ponse complÃ¨te basÃ©e uniquement sur le document

> Ce log montre que le systÃ¨me comprend le type de tÃ¢che demandÃ©, rÃ©cupÃ¨re les
> bons passages, puis gÃ©nÃ¨re un rÃ©sumÃ© structurÃ© et exploitable.

<p align="center">
  <img src="docs/screenshots/debug_logs.png" width="88%">
</p>
---

##  Extraction & analyse ciblÃ©e dâ€™un tableau (PDF rÃ©el)

Voici un test effectuÃ© sur *PC_Insurers_Filings.pdf*.  
Lâ€™objectif Ã©tait de filtrer un tableau rÃ©glementaire selon des critÃ¨res prÃ©cis :

 **Question demandÃ©e au modÃ¨le :**

> Ã€ partir du tableau page 1, extraire uniquement les dÃ©pÃ´ts qui :  
> â€¢ ont une date limite fixÃ©e au **3/1**  
> â€¢ sont soumis en **EO (Electronic-Only)**  
> â€¢ en fournissant : **Nom du dÃ©pÃ´t | Source | Copies requises | Notes**

 **RÃ©sultat gÃ©nÃ©rÃ© automatiquement**

<p align="center">
  <img src="docs/screenshots/table_analysis.png" width="90%">
</p>

Le modÃ¨le a correctement reconstruit les lignes du tableau, filtrÃ© les dÃ©pÃ´ts correspondants Ã  la date **3/1**,  
identifiÃ© que la plupart sont gÃ©rÃ©s via **envoi Ã©lectronique (EO)** et a prÃ©cisÃ© lâ€™origine des exigences (State / NAIC).

**RÃ©sumÃ© automatique extrait par le pipeline :**

> Les dÃ©pÃ´ts attendus au 3/1 sont majoritairement des fichiers EO.  
> La plupart proviennent des autoritÃ©s *State level*, avec plusieurs sÃ©ries rÃ©pÃ©tÃ©es, indiquant un flux administratif standardisÃ©.
---

##  Debug complet â€” Analyse dâ€™un PDF avec tableau (PC_Insurers_Filings.pdf)

Cette exÃ©cution montre le fonctionnement interne du pipeline sur un PDF rÃ©el de type rÃ©glementaire.  
On visualise clairement chaque Ã©tape du traitement : extraction, chunking, embeddings, indexation, retrieval, classification, gÃ©nÃ©ration.

<p align="center">
  <img src="docs/screenshots/debug_table_anlaysis_log.png" width="90%">
</p>

###  DÃ©roulement visible dans les logs

| Ã‰tape | DÃ©tails | Temps |
|---|---|---|
| Docling PDF â†’ Markdown | Extraction du tableau + contenu brut | ~229s |
| Chunking | Segmentation en 27 blocs â‰¤ 2048 tokens | 0.08s |
| Embeddings Qwen3 | GÃ©nÃ©ration + vectorisation | ~129s |
| Index FAISS | Construction instantanÃ©e | 0.11s |
| Retrieval Top-3 | Recherche des lignes pertinentes | 4.2s |
| Classification de requÃªte | `RÃ©sumÃ©`: **0.993** â†’ tÃ¢che dÃ©tectÃ©e automatiquement | 19.5s |
| RÃ©ponse finale | SynthÃ¨se + format structurÃ© | 256.7s |
| **DurÃ©e complÃ¨te du pipeline** | 639.6s | â¬… exÃ©cution multimodale lourde |

*Le pipeline identifie automatiquement que la requÃªte correspond Ã  un rÃ©sumÃ© tabulaire (`classifier_score=0.993`) â€” preuve quâ€™il comprend la nature de la tÃ¢che.*

---

### Ce que ce log prouve techniquement

| CompÃ©tence du systÃ¨me | âœ” ValidÃ©e |
|---|:---:|
| Traitement de PDF complexe | âœ” |
| Conversion en Markdown + chunks structurÃ©s | âœ” |
| Embeddings + indexation vectorielle | âœ” |
| RÃ©cupÃ©ration top-k + classification intelligente | âœ” |
| RÃ©sumÃ© automatique exploitable | âœ” |



---

---

## ğŸ“„ Documents PDF utilisÃ©s pour les tests

Pour assurer la reproductibilitÃ© complÃ¨te, voici les fichiers PDF utilisÃ©s dans les exemples du README.  
Ils sont disponibles dans le repository pour permettre Ã  d'autres utilisateurs de tester le pipeline eux-mÃªmes.

| PDF | Contenu | Lien |
|---|---|---|
| `PC_Insurers_Filings.pdf` | Tableau rÃ©glementaire + choix multiples (Source/Notes/EO) | ğŸ”— [TÃ©lÃ©charger](docs/pdfs/PC_Insurers_Filings.pdf) |
| `Jadi_Amine_CV_2026 (1).pdf` | CV_fichier_textuel| ğŸ”— [TÃ©lÃ©charger](docs/pdfs/Jadi_Amine_CV_2026(1).pdf) |


> Chaque fichier peut Ãªtre ouvert et analysÃ© directement via lâ€™interface RAG_PDF.

---

##  DonnÃ©es & sÃ©curitÃ©

- Traitement **local** par dÃ©faut (pas dâ€™envoi cloud non configurÃ©).  
- Les PDFs sont renommÃ©s par hash dans `data/uploads/`.  
- Pensez Ã  ignorer `data/` dans Git :

```gitignore
data/
*.log
*.cache
```

---

##  Exemple dâ€™utilisation (placeholders)

Place tes captures dâ€™Ã©cran dans `docs/screenshots/` :

- `docs/screenshots/ui_upload.png` â€” Upload + choix du mode  
- `docs/screenshots/ui_response.png` â€” RÃ©ponse + top-k + rÃ©sumÃ© VLM  

---

## ğŸ‘¤ Auteur

**Ahmed Amine Jadi** â€” 2025  
Stage ingÃ©nieur â€” *AtlantaSanad Assurance*

- GitHub : https://github.com/JADIAhmedAmine
- LinkedIn : https://www.linkedin.com/in/ahmed-amine-jadi-958010373/  
- Email : amine_jadon@outlook.fr

---

##  Licence

MIT â€” voir `LICENSE`.
